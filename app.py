import streamlit as st
import os
import json
import time
import requests  # Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
import google.generativeai as genai
from elevenlabs.client import ElevenLabs
from moviepy.editor import VideoFileClip

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(
    page_title="Ø§Ø³ØªÙˆØ¯ÙŠÙˆ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø°ÙƒÙŠ",
    page_icon="ğŸ¬",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# --- 2. Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ---
def load_api_keys():
    try:
        GOOGLE_KEY = st.secrets["GOOGLE_API_KEY"]
        ELEVEN_KEY = st.secrets["ELEVENLABS_API_KEY"]
        return GOOGLE_KEY, ELEVEN_KEY
    except:
        st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ù…Ù„Ù secrets.toml")
        st.stop()

GOOGLE_API_KEY, ELEVENLABS_API_KEY = load_api_keys()
genai.configure(api_key=GOOGLE_API_KEY)
eleven_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)

# --- 3. Ù…ÙˆØ¯ÙŠÙ„ Gemini ---
@st.cache_resource
def get_working_model_name():
    try:
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        for m in models: 
            if 'gemini-1.5-flash' in m: return m
        if models: return models[0]
    except: pass
    return "models/gemini-1.5-flash"

CURRENT_MODEL_NAME = get_working_model_name()

# --- 4. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø§Ù„Ø© ---
if 'dubbed_video' not in st.session_state: st.session_state['dubbed_video'] = None
if 'generated_clips' not in st.session_state: st.session_state['generated_clips'] = []
if 'dubbed_clips_results' not in st.session_state: st.session_state['dubbed_clips_results'] = []

# --- 5. Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ---

def check_video_duration(video_path, max_minutes=5):
    try:
        clip = VideoFileClip(video_path)
        dur = clip.duration
        clip.close()
        if dur > max_minutes * 60: return False, dur
        return True, dur
    except: return True, 0

def render_header(image_name, alt_text):
    if os.path.exists(image_name):
        st.image(image_name, use_column_width=True)
    else:
        st.header(alt_text)

# === (Ø§Ù„Ø­Ù„ Ø§Ù„Ø¬Ø°Ø±ÙŠ) Ø¯Ø¨Ù„Ø¬Ø© Ø¨Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± API Request ===
def process_full_dubbing(video_path, target_lang_code):
    try:
        # Ø±Ø§Ø¨Ø· Ø®Ø¯Ù…Ø© Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
        url = "https://api.elevenlabs.io/v1/dubbing"
        
        headers = {
            "xi-api-key": ELEVENLABS_API_KEY
        }
        
        # 1. Ø¥Ø±Ø³Ø§Ù„ Ù…Ù„Ù Ø§Ù„ÙÙŠØ¯ÙŠÙˆ (POST)
        with open(video_path, "rb") as f:
            data = {
                "target_lang": target_lang_code,
                "mode": "automatic",
                "source_lang": "auto",
                "num_speakers": "0",
                "watermark": "false"
            }
            files = {"file": f}
            
            response = requests.post(url, headers=headers, data=data, files=files)
        
        if response.status_code != 200:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø³ÙŠØ±ÙØ±: {response.text}")
            return None
            
        dubbing_id = response.json().get("dubbing_id")
        
        # 2. Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (Polling)
        progress_text = "Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø© ÙˆØ§Ù„Ù…Ø²Ø§Ù…Ù†Ø© (Pro)..."
        my_bar = st.progress(0, text=progress_text)
        
        while True:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø§Ù„Ø©
            status_url = f"https://api.elevenlabs.io/v1/dubbing/{dubbing_id}"
            status_response = requests.get(status_url, headers=headers)
            status_data = status_response.json()
            
            status = status_data.get("status")
            
            if status == "dubbed":
                my_bar.progress(100, text="ØªÙ…Øª Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø© Ø¨Ù†Ø¬Ø§Ø­!")
                break
            elif status == "failed":
                st.error("ÙØ´Ù„Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø© ÙÙŠ Ø§Ù„Ù…ØµØ¯Ø±.")
                return None
            else:
                time.sleep(2) # Ø§Ù†ØªØ¸Ø§Ø±
        
        # 3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø¬Ø§Ù‡Ø²
        # Ù…Ù„Ø§Ø­Ø¸Ø©: Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù†Ø³ØªØ®Ø¯Ù… Ø±Ø§Ø¨Ø· Ø®Ø§Øµ
        download_url = f"https://api.elevenlabs.io/v1/dubbing/{dubbing_id}/audio/{target_lang_code}"
        
        dl_response = requests.get(download_url, headers=headers, stream=True)
        
        output_path = "final_dubbed_video.mp4"
        
        if dl_response.status_code == 200:
            with open(output_path, "wb") as f:
                for chunk in dl_response.iter_content(chunk_size=1024):
                    f.write(chunk)
            return output_path
        else:
            st.error(f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {dl_response.text}")
            return None

    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
        return None

# === Ø¯Ø§Ù„Ø© Ø§Ù„Ù‚Øµ Ø§Ù„Ø°ÙƒÙŠ ===
def analyze_and_cut_specific(video_path, num_clips, clip_duration, prefix="clip"):
    model = genai.GenerativeModel(CURRENT_MODEL_NAME)
    video_clip = VideoFileClip(video_path)
    total_duration = video_clip.duration
    video_clip.close()
    
    try:
        myfile = genai.upload_file(video_path)
        while myfile.state.name == "PROCESSING":
            time.sleep(1)
            myfile = genai.get_file(myfile.name)
            
        prompt = f"""
        Analyze this video. Find exactly {num_clips} best segments.
        Each segment MUST be exactly {clip_duration} seconds long.
        Return valid JSON only: [{{ "start": 10, "end": {10+clip_duration}, "label": "Topic" }}]
        Timestamps must be within 0 and {total_duration}.
        """
        response = model.generate_content([prompt, myfile])
        text = response.text.replace("```json", "").replace("```", "").strip()
        timestamps = json.loads(text)
    except: 
        timestamps = []
        for i in range(num_clips):
            start = i * clip_duration
            if start + clip_duration > total_duration: break
            timestamps.append({"start": start, "end": start + clip_duration, "label": f"Clip {i+1}"})

    video = VideoFileClip(video_path)
    generated_files = []
    for i, item in enumerate(timestamps):
        try:
            start = float(item.get('start'))
            end = start + float(clip_duration)
            if end > video.duration: end = video.duration
            if start >= end: continue
            label = item.get('label', f'{prefix} {i+1}')
            clip = video.subclip(start, end)
            name = f"{prefix}_{i}_{label}.mp4".replace(" ", "_")
            clip.write_videofile(name, codec="libx264", audio_codec="aac", preset="ultrafast", threads=4, logger=None)
            generated_files.append({"path": name, "label": label})
        except: continue
    video.close()
    return generated_files

# --- 6. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (UI) ---
render_header("banner.jpg", "Ø§Ø³ØªÙˆØ¯ÙŠÙˆ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø°ÙƒÙŠ")
st.caption("Ø£ØªÙ…ØªØ© ØµÙ†Ø§Ø¹Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù…ÙŠ (Pro Edition)")

st.markdown("### 1. Ø±ÙØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ")
upload_option = st.radio("Ø§Ù„Ù…ØµØ¯Ø±:", ["Ø±ÙØ¹ Ù…Ù„Ù", "Ø±Ø§Ø¨Ø· ÙŠÙˆØªÙŠÙˆØ¨ (ÙÙŠØ¯ÙŠÙˆ Demo)"], horizontal=True)
video_path = None

if upload_option == "Ø±ÙØ¹ Ù…Ù„Ù":
    uploaded_file = st.file_uploader("Ù…Ù„Ù MP4", type=["mp4"])
    if uploaded_file:
        with open("temp_video.mp4", "wb") as f: f.write(uploaded_file.getbuffer())
        video_path = "temp_video.mp4"
elif upload_option == "Ø±Ø§Ø¨Ø· ÙŠÙˆØªÙŠÙˆØ¨ (ÙÙŠØ¯ÙŠÙˆ Demo)":
    yt_url = st.text_input("Ø£Ø¯Ø®Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ:", placeholder="https://www.youtube.com/watch?v=...")
    if st.button("ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ") and os.path.exists("sample.mp4"):
        video_path = "sample.mp4"
        st.success("ØªÙ… Ø¬Ù„Ø¨ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ù†Ø¬Ø§Ø­! (Demo Mode)")

if video_path:
    valid, dur = check_video_duration(video_path, 5)
    if not valid:
        st.error(f"Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø·ÙˆÙŠÙ„ ({int(dur/60)} Ø¯Ù‚ÙŠÙ‚Ø©).")
    else:
        st.video(video_path)
        st.divider()
        col_dub, col_cut = st.columns(2)

        with col_dub:
            render_header("dubbing.png", "ğŸ™ï¸ Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø©")
            st.markdown("---")
            lang_map = {"Arabic": "ar", "English": "en", "French": "fr", "Spanish": "es", "German": "de", "Chinese": "zh"}
            target_lang_name = st.selectbox("Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©", list(lang_map.keys()))
            
            if st.button("ğŸš€ ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø© (Pro)", use_container_width=True):
                st.session_state['dubbed_video'] = None
                with st.status("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ø³ØªÙˆØ¯ÙŠÙˆ Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø©...", expanded=True) as status:
                    status.write("1. Ø±ÙØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ†...")
                    final_vid = process_full_dubbing(video_path, lang_map[target_lang_name])
                    if final_vid:
                        st.session_state['dubbed_video'] = final_vid
                        status.update(label="âœ… ØªÙ…Øª Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø© ÙˆØ§Ù„Ù…Ø²Ø§Ù…Ù†Ø©!", state="complete")
                    else:
                        status.update(label="âŒ ÙØ´Ù„Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©", state="error")

        with col_cut:
            render_header("clipping.png", "âœ‚ï¸ Ø§Ù„Ù‚Øµ Ø§Ù„Ø°ÙƒÙŠ (Ù„Ù„Ø£ØµÙ„)")
            st.markdown("---")
            num_clips = st.number_input("Ø§Ù„Ø¹Ø¯Ø¯", 1, 5, 2, key="on")
            clip_dur = st.number_input("Ø§Ù„Ù…Ø¯Ø©", 10, 60, 20, key="od")
            if st.button("ğŸš€ Ù‚Øµ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø£ØµÙ„ÙŠ", use_container_width=True):
                st.session_state['generated_clips'] = []
                with st.status("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù‚Øµ...", expanded=True) as status:
                    clips = analyze_and_cut_specific(video_path, num_clips, clip_dur, prefix="orig")
                    if clips:
                        st.session_state['generated_clips'] = clips
                        status.update(label="âœ… ØªÙ… Ø§Ù„Ù‚Øµ!", state="complete")
                    else:
                        status.update(label="âŒ Ø®Ø·Ø£", state="error")

        st.divider()
        st.header("Ø§Ù„Ù†ØªØ§Ø¦Ø¬")

        if st.session_state['dubbed_video']:
            st.subheader("ğŸ¥ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ø¯Ø¨Ù„Ø¬")
            st.video(st.session_state['dubbed_video'])
            with open(st.session_state['dubbed_video'], "rb") as f:
                st.download_button("ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¯Ø¨Ù„Ø¬", f, "dubbed_pro.mp4")
            
            st.markdown("---")
            st.write("âœ‚ï¸ **Ù‚Øµ Ø§Ù„Ù…Ø¯Ø¨Ù„Ø¬:**")
            c1, c2, c3 = st.columns([1,1,1])
            with c1: dn = st.number_input("Ø§Ù„Ø¹Ø¯Ø¯", 1, 5, 2, key="dn")
            with c2: dd = st.number_input("Ø§Ù„Ù…Ø¯Ø©", 10, 60, 20, key="dd")
            with c3:
                st.write("")
                st.write("")
                if st.button("Ù‚Øµ Ø§Ù„Ø¢Ù†"):
                    st.session_state['dubbed_clips_results'] = analyze_and_cut_specific(st.session_state['dubbed_video'], dn, dd, prefix="dub")
            
            if st.session_state['dubbed_clips_results']:
                dc = st.columns(len(st.session_state['dubbed_clips_results']))
                for i, clip in enumerate(st.session_state['dubbed_clips_results']):
                    with dc[i]:
                        st.video(clip['path'])
                        with open(clip['path'], "rb") as f: st.download_button("ğŸ“¥", f, clip['path'], key=f"d{i}")

        if st.session_state['generated_clips']:
            st.subheader("âœ‚ï¸ Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ø£ØµÙ„")
            oc = st.columns(len(st.session_state['generated_clips']))
            for i, clip in enumerate(st.session_state['generated_clips']):
                with oc[i]:
                    st.video(clip['path'])
                    with open(clip['path'], "rb") as f: st.download_button("ğŸ“¥", f, clip['path'], key=f"o{i}")