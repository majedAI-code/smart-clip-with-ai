import streamlit as st
import os
import json
import time
import socket
import google.generativeai as genai
from elevenlabs.client import ElevenLabs
from moviepy.editor import VideoFileClip, AudioFileClip
import yt_dlp

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø¨ØµØ±ÙŠØ© ---
st.set_page_config(
    page_title="Ø§Ø³ØªÙˆØ¯ÙŠÙˆ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø°ÙƒÙŠ",
    page_icon="ğŸ¬",
    layout="centered"
)

# --- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ---
def load_api_keys():
    try:
        GOOGLE_KEY = st.secrets["GOOGLE_API_KEY"]
        ELEVEN_KEY = st.secrets["ELEVENLABS_API_KEY"]
        return GOOGLE_KEY, ELEVEN_KEY
    except:
        st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ ÙˆØ¶Ø¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ÙÙŠ Secrets")
        st.stop()

GOOGLE_API_KEY, ELEVENLABS_API_KEY = load_api_keys()

genai.configure(api_key=GOOGLE_API_KEY)
eleven_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)

# --- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Session State) Ù„Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ø®ØªÙØ§Ø¡ Ø§Ù„ØªØ­Ù…ÙŠÙ„ ---
if 'processed' not in st.session_state:
    st.session_state['processed'] = False
if 'dubbed_video' not in st.session_state:
    st.session_state['dubbed_video'] = None
if 'clips_list' not in st.session_state:
    st.session_state['clips_list'] = []

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ---

def check_video_duration(video_path, max_minutes=5):
    try:
        clip = VideoFileClip(video_path)
        duration_sec = clip.duration
        clip.close()
        if duration_sec > (max_minutes * 60):
            return False, duration_sec
        return True, duration_sec
    except:
        return True, 0

def get_best_model():
    return 'models/gemini-1.5-flash'

CURRENT_MODEL_NAME = get_best_model()

def detect_speaker_gender(audio_path):
    model = genai.GenerativeModel(CURRENT_MODEL_NAME)
    try:
        with open(audio_path, "rb") as f:
            audio_data = f.read()
        prompt = "Listen to this audio. Identify the gender of the MAIN speaker. Return ONLY one word: 'Male' or 'Female'."
        response = model.generate_content([prompt, {"mime_type": "audio/mp3", "data": audio_data}])
        if "female" in response.text.strip().lower(): return "female"
        return "male"
    except: return "male"

def extract_audio(video_path):
    video = VideoFileClip(video_path)
    audio_path = "temp_audio.mp3"
    video.audio.write_audiofile(audio_path, logger=None)
    video.close()
    return audio_path

def transcribe_and_translate(audio_path, target_lang):
    model = genai.GenerativeModel(CURRENT_MODEL_NAME)
    with open(audio_path, "rb") as f: audio_data = f.read()
    prompt = f"Listen to this audio. Transcribe and translate the content to {target_lang}. Return ONLY the translated text suitable for dubbing."
    result = model.generate_content([prompt, {"mime_type": "audio/mp3", "data": audio_data}])
    return result.text

def generate_dubbed_audio(text, voice_id):
    try:
        audio_generator = eleven_client.text_to_speech.convert(
            text=text, voice_id=voice_id, model_id="eleven_multilingual_v2"
        )
        save_path = "dubbed_audio.mp3"
        with open(save_path, "wb") as f:
            for chunk in audio_generator: f.write(chunk)
        return save_path
    except Exception as e:
        st.warning(f"âš ï¸ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø© Ø¨Ø³Ø¨Ø¨: {e}")
        return None

def merge_audio_video(video_path, audio_path):
    video = VideoFileClip(video_path)
    new_audio = AudioFileClip(audio_path)
    final_video = video.set_audio(new_audio)
    if new_audio.duration < video.duration:
        final_video = final_video.subclip(0, new_audio.duration)
    output_path = "final_dubbed_video.mp4"
    final_video.write_videofile(output_path, codec="libx264", audio_codec="aac", logger=None)
    video.close()
    new_audio.close()
    return output_path

# --- Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: Ø§Ù„Ù‚Øµ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ ---
def get_viral_clips_dynamic(video_path):
    model = genai.GenerativeModel(CURRENT_MODEL_NAME)
    myfile = genai.upload_file(video_path)
    while myfile.state.name == "PROCESSING":
        time.sleep(2)
        myfile = genai.get_file(myfile.name)
    
    # Ù‡Ù†Ø§ Ø§Ù„Ø°ÙƒØ§Ø¡: Ù„Ø§ Ù†Ø·Ù„Ø¨ Ø¹Ø¯Ø¯Ø§Ù‹ Ù…Ø­Ø¯Ø¯Ø§Ù‹ØŒ Ù†Ø·Ù„Ø¨ Ù…Ù†Ù‡ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£ÙØ¶Ù„ ÙÙ‚Ø·
    prompt = """
    Analyze the video carefully. Identify the MOST viral and engaging segments (Shorts/Reels).
    - Select only segments that stand out (funny, insightful, shocking, or summarized).
    - Duration of each clip: between 15 to 60 seconds.
    - Return a JSON list: [{"start": 10, "end": 40, "label": "Topic 1"}, ...]
    - If the video is boring, return an empty list.
    """
    try:
        response = model.generate_content([prompt, myfile])
        text = response.text.replace("```json", "").replace("```", "").strip()
        return json.loads(text)
    except: return []

def cut_clips_processing(original_video_path, timestamps):
    video = VideoFileClip(original_video_path)
    generated_files = []
    for i, item in enumerate(timestamps):
        start = item.get('start')
        end = item.get('end')
        label = item.get('label', f'Clip {i+1}')
        try:
            clip = video.subclip(start, end)
            # ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø±Ø£Ø³ÙŠØ© Ù„Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„ (Ø§Ø®ØªÙŠØ§Ø±ÙŠØŒ Ù‡Ù†Ø§ Ù†Ù‚Øµ ÙÙ‚Ø·)
            output_name = f"clip_{i+1}_{label}.mp4"
            clip.write_videofile(output_name, codec="libx264", audio_codec="aac", logger=None)
            generated_files.append({"path": output_name, "label": label})
        except: continue
    video.close()
    return generated_files

# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ---

st.title("Ø§Ø³ØªÙˆØ¯ÙŠÙˆ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø°ÙƒÙŠ")
st.caption("Ø£ØªÙ…ØªØ© ØµÙ†Ø§Ø¹Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù…ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ÙŠ")

# 1. Ù‚Ø³Ù… Ø§Ù„Ø±ÙØ¹
st.header("1. Ø±ÙØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ")
upload_option = st.radio("Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©:", ["Ø±ÙØ¹ Ù…Ù„Ù", "ÙÙŠØ¯ÙŠÙˆ ØªØ¬Ø±ÙŠØ¨ÙŠ (Demo)"], horizontal=True)
video_path = None

if upload_option == "Ø±ÙØ¹ Ù…Ù„Ù":
    uploaded_file = st.file_uploader("Ø§Ø®ØªØ± Ù…Ù„Ù MP4", type=["mp4"])
    if uploaded_file:
        with open("temp_video.mp4", "wb") as f: f.write(uploaded_file.getbuffer())
        video_path = "temp_video.mp4"
elif upload_option == "ÙÙŠØ¯ÙŠÙˆ ØªØ¬Ø±ÙŠØ¨ÙŠ (Demo)":
    if os.path.exists("sample.mp4"):
        video_path = "sample.mp4"
        st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ")
    else:
        st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ sample.mp4")

if video_path:
    # ÙØ­Øµ Ø§Ù„Ù…Ø¯Ø©
    valid, dur = check_video_duration(video_path, 5)
    if not valid:
        st.error(f"ÙÙŠØ¯ÙŠÙˆ Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ø§Ù‹ ({int(dur/60)} Ø¯Ù‚ÙŠÙ‚Ø©). Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ 5 Ø¯Ù‚Ø§Ø¦Ù‚.")
        st.stop()
    
    st.video(video_path)
    
    st.divider()
    st.header("2. Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø© Ø§Ù„Ø°ÙƒÙŠØ©")
        st.caption("Smart Dubbing")
        enable_dubbing = st.checkbox("ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø©")
        target_lang = st.selectbox("Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©", ["English", "Arabic", "French", "Spanish", "Chinese"])
        
    with col2:
        st.subheader("Ø§Ù„Ù‚Øµ Ø§Ù„Ø°ÙƒÙŠ")
        st.caption("Viral Clipping")
        enable_clipping = st.checkbox("Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ø£ÙƒØ«Ø± Ø±ÙˆØ§Ø¬Ø§Ù‹")
        st.info("ğŸ¤– Ø³ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ ÙˆÙ…Ø¯Ù‘Ø© Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰.")

    # Ø²Ø± Ø§Ù„ØªØ´ØºÙŠÙ„
    if st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"):
        st.session_state['processed'] = True # Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø£Ù†Ù†Ø§ Ø¨Ø¯Ø£Ù†Ø§
        st.session_state['dubbed_video'] = None
        st.session_state['clips_list'] = [] # ØªØµÙÙŠØ± Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        
        with st.status("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¹Ù…Ù„ ÙÙŠ Ø§Ù„Ø§Ø³ØªÙˆØ¯ÙŠÙˆ...", expanded=True) as status:
            
            # --- Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø© ---
            if enable_dubbing:
                status.write("ğŸ™ï¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª ÙˆØ§Ù„Ù‡ÙˆÙŠØ©...")
                audio_path = extract_audio(video_path)
                gender = detect_speaker_gender(audio_path)
                
                status.write(f"detected gender: {gender}. Translating...")
                translated_text = transcribe_and_translate(audio_path, target_lang)
                
                # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØµÙˆØª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ù†Ø³
                voice_id = "21m00Tcm4TlvDq8ikWAM" if gender == "female" else "pNInz6obpgDQGcFmaJgB"
                
                status.write("ğŸ—£ï¸ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø©...")
                dubbed_audio = generate_dubbed_audio(translated_text, voice_id)
                
                if dubbed_audio:
                    final_video = merge_audio_video(video_path, dubbed_audio)
                    st.session_state['dubbed_video'] = final_video
                else:
                    st.warning("ØªÙ… ØªØ®Ø·ÙŠ Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø© Ù„Ø³Ø¨Ø¨ ØªÙ‚Ù†ÙŠØŒ Ø³ÙŠØªÙ… Ø¹Ø±Ø¶ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø£ØµÙ„ÙŠ.")

            # --- Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚Øµ Ø§Ù„Ø°ÙƒÙŠ ---
            if enable_clipping:
                status.write("ğŸ§  Gemini ÙŠØ´Ø§Ù‡Ø¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙˆÙŠØ­Ø¯Ø¯ Ø§Ù„Ù„Ù‚Ø·Ø§Øª Ø§Ù„ÙÙŠØ±ÙˆØ³ÙŠØ©...")
                # Ù‡Ù†Ø§ Ù„Ø§ Ù†Ø­Ø¯Ø¯ Ø§Ù„Ø¹Ø¯Ø¯ØŒ Ù†ØªØ±Ùƒ Gemini ÙŠÙ‚Ø±Ø±
                clips_data = get_viral_clips_dynamic(video_path)
                
                if clips_data:
                    status.write(f"âœ‚ï¸ ÙˆØ¬Ø¯Ù†Ø§ {len(clips_data)} Ù…Ù‚Ø§Ø·Ø¹ Ù…Ù…ÙŠØ²Ø©. Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù‚Øµ...")
                    generated_clips = cut_clips_processing(video_path, clips_data)
                    st.session_state['clips_list'] = generated_clips
                else:
                    st.warning("Ù„Ù… ÙŠØ¬Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ù‚Ø§Ø·Ø¹ ÙÙŠØ±ÙˆØ³ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ.")
            
            status.update(label="âœ… ØªÙ…Øª Ø§Ù„Ù…Ù‡Ù…Ø©!", state="complete")

# --- Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Ù…ÙØµÙˆÙ„ Ø¹Ù† Ø§Ù„Ø²Ø± Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø«Ø¨Ø§Øª) ---
if st.session_state['processed']:
    st.divider()
    st.header("3. Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    # 1. Ø¹Ø±Ø¶ Ø§Ù„Ø¯Ø¨Ù„Ø¬Ø©
    if st.session_state['dubbed_video']:
        st.subheader("ğŸ¥ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ø¯Ø¨Ù„Ø¬")
        st.video(st.session_state['dubbed_video'])
        with open(st.session_state['dubbed_video'], "rb") as f:
            st.download_button("ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ø¯Ø¨Ù„Ø¬", f, file_name="dubbed_video.mp4")
    
    # 2. Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù…Ù‚ØµÙˆØµØ©
    if st.session_state['clips_list']:
        st.subheader("ğŸ”¥ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ø£ÙƒØ«Ø± Ø±ÙˆØ§Ø¬Ø§Ù‹ (Viral Clips)")
        cols = st.columns(len(st.session_state['clips_list'])) if len(st.session_state['clips_list']) > 0 else [st.container()]
        
        for i, clip in enumerate(st.session_state['clips_list']):
            # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø¨Ø´ÙƒÙ„ Ø¬Ù…ÙŠÙ„
            st.write(f"**ğŸ“Œ {clip['label']}**")
            st.video(clip['path'])
            with open(clip['path'], "rb") as f:
                # Ø§Ù„Ù…ÙØªØ§Ø­ (key) Ù‡Ù†Ø§ Ù‡Ùˆ Ø§Ù„Ø³Ø± Ù„Ø¹Ø¯Ù… Ø§Ø®ØªÙØ§Ø¡ Ø§Ù„Ø£Ø²Ø±Ø§Ø±
                st.download_button(
                    label=f"ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø·Ø¹ {i+1}",
                    data=f,
                    file_name=clip['path'],
                    key=f"btn_{i}" 
                )
            st.divider()